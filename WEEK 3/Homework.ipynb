{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "New York City Airbnb Open Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv'\r\n",
    "\r\n",
    "!wget $data -O data-homework.csv\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<H2> DATA PREPARATION</H2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_csv('data-homework.csv')\r\n",
    "\r\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "categorical = [\r\n",
    "'neighbourhood_group',\r\n",
    "'room_type',\r\n",
    "]\r\n",
    "\r\n",
    "numerical=['latitude',\r\n",
    "'longitude',\r\n",
    "'price',\r\n",
    "'minimum_nights',\r\n",
    "'number_of_reviews',\r\n",
    "'reviews_per_month',\r\n",
    "'calculated_host_listings_count',\r\n",
    "'availability_365']\r\n",
    "\r\n",
    " "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " fill in the missing values with 0."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prepare_df(df):\r\n",
    "    df_copy = df[categorical+numerical]\r\n",
    "    df_copy = df_copy.fillna(0)\r\n",
    "    df_copy.price = (df_copy.price >= 152).astype(int)\r\n",
    "    return df_copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_copy = prepare_df(df)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_copy.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<b>Question 1</b> <br>\r\n",
    "What is the most frequent observation (mode) for the column 'neighbourhood_group'?\r\n",
    "\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display(df_copy.mode()['neighbourhood_group'][0]);\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "### Split the data\r\n",
    "\r\n",
    "* Split your data in train/val/test sets, with 60%/20%/20% distribution.\r\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to 42.\r\n",
    "* Make sure that the target value ('price') is not in your dataframe."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(df_copy)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "df_full_train , df_test =train_test_split(df_copy,test_size=0.2,random_state=42) # Using 20% test Size seed 42\r\n",
    "\r\n",
    "# df_full_train = 80% of df_copy\r\n",
    "# df_test = 20% of df_copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(df_full_train),len(df_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train , df_val = train_test_split(df_full_train,test_size=0.25,random_state=42) # From full train split "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "len(df_train) , len(df_val) , len (df_test) \r\n",
    "\r\n",
    "# validation data set of full train \r\n",
    "# df_full_train = 80% of df_copy\r\n",
    "# df_test = 20% of df_copy\r\n",
    "# df_val = 20% of df_copy and 25% of df_full_train\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train= df_train.reset_index(drop=True) # not necessary for models to work\r\n",
    "df_val = df_val.reset_index(drop=True) # not necessary for models to work\r\n",
    "df_test = df_test.reset_index(drop=True) # not necessary for models to work\r\n",
    "df_full_train = df_full_train.reset_index(drop=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train = df_train.price.values\r\n",
    "y_val = df_val.price.values\r\n",
    "y_test = df_test.price.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "del df_train['price']\r\n",
    "del df_val['price']\r\n",
    "del df_test['price']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2\r\n",
    "\r\n",
    "* Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your train dataset.\r\n",
    "   * In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\r\n",
    "* What are the two features that have the biggest correlation in this dataset?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "### Make price binary\r\n",
    "\r\n",
    "* We need to turn the price variable from numeric into binary.\r\n",
    "* Let's create a variable `above_average` which is `1` if the price is above (or equal to) `152`.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_full_train.price"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_full_train.price.value_counts()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.corr().unstack().sort_values(ascending=False).drop_duplicates()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.heatmap(df_train.corr())\r\n",
    "# for better visualization of correlation values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 3\r\n",
    "\r\n",
    "* Calculate the mutual information score with the (binarized) price for the two categorical variables that we have. Use the training set only.\r\n",
    "* Which of these two variables has bigger score?\r\n",
    "* Round it to 2 decimal digits using `round(score, 2)`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import mutual_info_score\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "display(round(mutual_info_score(df_full_train.price,df_full_train.neighbourhood_group),2)) # mutual information score\r\n",
    "\r\n",
    "display(round(mutual_info_score(df_full_train.price,df_full_train.room_type),2)) # mutual information score\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_full_train.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4\r\n",
    "\r\n",
    "* Now let's train a logistic regression\r\n",
    "* Remember that we have two categorical variables in the data. Include them using one-hot encoding.\r\n",
    "* Fit the model on the training dataset.\r\n",
    "   * To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\r\n",
    "   * `model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42)`\r\n",
    "* Calculate the accuracy on the validation dataset and rount it to 2 decimal digits.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_train.dtypes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\r\n",
    "\r\n",
    "\r\n",
    "base_features = (categorical + numerical).copy()\r\n",
    "\r\n",
    "base_features.remove('price') # Removing the price \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "train_dict= df_train[ base_features ].to_dict(orient='records') # creating a dictionary from the data\r\n",
    "\r\n",
    "train_dict[0]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dv = DictVectorizer(sparse=False) # turn the dictionary into a vector\r\n",
    "dv.fit(train_dict)\r\n",
    "X_train = dv.transform(train_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dv.get_feature_names()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Logistic Regression </h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "$$\\sigma = \\frac{1}{1+exp(-z)}$$"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Training logic regression with Scikit-Learn </h2>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42,max_iter=10000)\r\n",
    "model.fit(X_train, y_train)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_dict = df_val[base_features].to_dict(orient='records')\r\n",
    "X_val = dv.transform(val_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.coef_[0].round(2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.predict_proba(X_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred = model.predict_proba(X_val)[:, 1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "price_predict = (y_pred > 0.5).astype(int)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "( y_val == price_predict).mean()\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\r\n",
    "### Question 5\r\n",
    "\r\n",
    "* We have 9 features: 7 numerical features and 2 categorical.\r\n",
    "* Let's find the least useful one using the *feature elimination* technique.\r\n",
    "* Train a model with all these features (using the same parameters as in Q4).\r\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\r\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \r\n",
    "* Which of following feature has the smallest difference? \r\n",
    "   * `neighbourhood_group`\r\n",
    "   * `room_type` \r\n",
    "   * `number_of_reviews`\r\n",
    "   * `reviews_per_month`\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "base = [\r\n",
    "'neighbourhood_group',\r\n",
    "'room_type',\r\n",
    "'latitude',\r\n",
    "'longitude',\r\n",
    "'minimum_nights',\r\n",
    "'number_of_reviews',\r\n",
    "'reviews_per_month',\r\n",
    "'calculated_host_listings_count',\r\n",
    "'availability_365'\r\n",
    "]\r\n",
    "\r\n",
    "base1=base.copy()\r\n",
    "base1.remove('neighbourhood_group')\r\n",
    "\r\n",
    "\r\n",
    "base2=base.copy()\r\n",
    "base2.remove('room_type')\r\n",
    "\r\n",
    "base3=base.copy()\r\n",
    "base3.remove('latitude')\r\n",
    "\r\n",
    "\r\n",
    "base4=base.copy()\r\n",
    "base4.remove('reviews_per_month')\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "def Feature_model(new_base):\r\n",
    "    train_dicts= df_train[new_base].to_dict(orient='records') # creating a dictionary from the data\r\n",
    "    \r\n",
    "    dv = DictVectorizer(sparse=False) # turn the dictionary into a vector\r\n",
    "    X_train = dv.fit_transform(train_dicts) # building a one-hot enconding matrix out of the data\r\n",
    "    dv.fit(train_dicts) # SAME as above\r\n",
    "    X_train = dv.transform(train_dicts)\r\n",
    "    val_dict = df_val[new_base].to_dict(orient='records')\r\n",
    "    X_val = dv.transform(val_dict)\r\n",
    "\r\n",
    "    model = LogisticRegression(solver='lbfgs', C=1.0, random_state=42, max_iter=10000)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    model.predict(X_train\r\n",
    "    ) # HARD predictions \r\n",
    "    y_pred =model.predict_proba(X_val\r\n",
    "    )[:,1]\r\n",
    "    #LOGISTIC REGRESSION\r\n",
    "    price_predict = (y_pred > 0.5).astype(int)\r\n",
    "    original_accuracy= (y_val == price_predict).mean()\r\n",
    "\r\n",
    "    display(original_accuracy)\r\n",
    "\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "display(\"Removed neighbourhood_group:\")\r\n",
    "Feature_model(base1)\r\n",
    "\r\n",
    "display(\"Removed room_type:\")\r\n",
    "Feature_model(base2)\r\n",
    "\r\n",
    "display(\"Removed latitude:\")\r\n",
    "Feature_model(base3)\r\n",
    "\r\n",
    "display(\"Removed reviews_per_month\")\r\n",
    "Feature_model(base4)\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<i> Answer : reviews_per_month </i>\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 6\r\n",
    "\r\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn\r\n",
    "* We'll need to use the original column `'price'`. Apply the logarithmic transformation to this column.\r\n",
    "* Fit the Ridge regression model on the training data.\r\n",
    "* This model has a parameter `alpha`. Let's try the following values: `[0, 0.01, 0.1, 1, 10]`\r\n",
    "* Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits.\r\n",
    "\r\n",
    "If there are multiple options, select the smallest `alpha`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prepare_df_lr(df):\r\n",
    "    df_copy = df[categorical+numerical]\r\n",
    "    df_copy = df_copy.fillna(0)\r\n",
    "    return df_copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_lr = prepare_df_lr(df)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "source": [
    "df_lr.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "neighbourhood_group               0\n",
       "room_type                         0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "reviews_per_month                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 176
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit"
  },
  "interpreter": {
   "hash": "468f25ad0239460415b7e6b7483d5c8f7213894121f6fb96c4cb6ef93fffe534"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}